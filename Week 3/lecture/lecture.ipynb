{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 {\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".term {\n",
       "    text-align: center;\n",
       "    margin-top: 1em;\n",
       "    margin-bottom: 1em;\n",
       "}\n",
       "\n",
       ".organizers {\n",
       "    text-align: center;\n",
       "    margin-left: 20%;\n",
       "    margin-right: 20%;\n",
       "    margin-bottom: 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "h1 {\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".term {\n",
    "    text-align: center;\n",
    "    margin-top: 1em;\n",
    "    margin-bottom: 1em;\n",
    "}\n",
    "\n",
    ".organizers {\n",
    "    text-align: center;\n",
    "    margin-left: 20%;\n",
    "    margin-right: 20%;\n",
    "    margin-bottom: 1em;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "PyTorch version: 2.2.2\n",
      "Matplotlib version: 3.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Python Programming for Machine Learning</h1>\n",
    "\n",
    "<div class=\"term\">Tensor Operations</div>\n",
    "\n",
    "<div class=\"term\">Winter Term 2024/2025</div>\n",
    "\n",
    "<div class=\"organizers\">\n",
    "    Weronika Kłos\n",
    "</div>\n",
    "\n",
    "<center><img src='images/python-logo-only.svg' width=250> </center>\n",
    "<br>\n",
    "<div class=\"copyright\" style=\"margin-top: 10px; font-size: 0.9em;\">\n",
    "    © 2024 Jannik Wolff. Original content created by Jannik Wolff.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder:\n",
    "- Lecturer: Have you started the recording?\n",
    "- Audience: Have you received a notification that the recording has started?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture layout\n",
    "### 1. **Motivation:** why is learning tensor operations important?\n",
    "### 2. **Technical part:** how to code tensor operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantics\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; align-items: center; margin: 20px 0;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src='images/tensors.jpg' width=500 style=\"border: 1px solid #f0f0f0;\" alt=\"Tensors of different ranks\">\n",
    "  </div>\n",
    "  <div style=\"width: 80%; margin-top: 10px; text-align: center;\">\n",
    "    <p style=\"font-weight: 500; margin-bottom: 4px; font-size: 0.95em;\">Figure 1: Tensors of different ranks</p>\n",
    "    <p style=\"font-size: 0.8em; color: #555; font-style: italic;\">\n",
    "      Source: Adapted from Ravi Ranjan (2020). <a href=\"https://squaredr.medium.com/5-ways-of-creating-tensors-1dbb874d2ca4\" target=\"_blank\" style=\"color: #1a73e8;\">Blog post</a>\n",
    "    </p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Vector\n",
    "- 1D datastructure\n",
    "- Examples: text token sequences or amino acid sequences\n",
    "\n",
    "### Matrix\n",
    "- 2D datastructure with rows and columns:\n",
    "- Example: Black/white image, where each value is a pixel\n",
    "\n",
    "### Tensor\n",
    "- Generalization of a matrix to more dimensions\n",
    "- Vectors and matrices are special cases\n",
    "- Example: Color image, where each pixel has three color channels\n",
    "\n",
    "### Array\n",
    "- Programming abstraction for tensors\n",
    "- Example: tensors implemented in Python frameworks like NumPy or Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operators on arrays\n",
    "- Element-wise operations\n",
    "- Matrix multiplication\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications in machine learning\n",
    "Somewhat simplified: Data + operators = machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays and array operations are relevant almost everywhere in machine learning, e.g.:\n",
    "- **Generative modeling:** Transformers, diffusion models, ...\n",
    "- **Representation learning:** Decoder-free self-supervised learning, ...\n",
    "- **Search:** Monte-Carlo Tree search, ...\n",
    "- **Classical ML:** decision trees, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from a real codebase\n",
    "- [Attention implementation from Andrej Karpathy](https://github.com/karpathy/nanoGPT/blob/master/model.py#L52)\n",
    "- You do not need to understand this function at this point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our goals\n",
    "\n",
    "- Express complex data and complex functions operating on this data\n",
    "- Efficiency in terms of computation/memory\n",
    "- Readable/compact syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieving our goals is difficult with the Python standard library\n",
    "- Interpreted languages are slow for loops / can require redundant memory\n",
    "- Native Python syntax unnecessarily verbose for some linear algebra operations (like complex indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python libraries are more flexible\n",
    "- Acceleration frameworks like NumPy or Torch:\n",
    "  - Bindings to C code for efficiency\n",
    "  - Compact expressions for complicated structures\n",
    "- Two-language problem\n",
    "  - Any specialized use-case requires writing code in two languages\n",
    "  - Mainstream use cases: frameworks already exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; align-items: center; margin: 20px 0;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src='images/single-layer-net.png' width=300 style=\"border: 1px solid #f0f0f0;\" alt=\"Single layer neural network\">\n",
    "  </div>\n",
    "  <div style=\"width: 80%; margin-top: 10px; text-align: center;\">\n",
    "    <p style=\"font-weight: 500; margin-bottom: 4px; font-size: 0.95em;\">Figure 2: Single layer neural network architecture</p>\n",
    "    <p style=\"font-size: 0.8em; color: #555; font-style: italic;\">\n",
    "      Source: <a href=\"https://lucidar.me/en/neural-networks/single-layer-algorithm/\" target=\"_blank\" style=\"color: #1a73e8;\">Bolg post</a>\n",
    "    </p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 785), (785, 128))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input data\n",
    "input_size = 784 # eg. flattened 28x28 images\n",
    "output_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "inputs = [[random.random() for _ in range(input_size)] for _ in range(batch_size)]\n",
    "weights = [[random.random() for _ in range(output_size)] for _ in range(input_size + 1)]  # +1 for bias\n",
    "\n",
    "# Add bias term\n",
    "inputs = [input_sample + [1.0] for input_sample in inputs]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "inputs_np = np.array(inputs)\n",
    "weights_np = np.array(weights)\n",
    "inputs_np.shape, weights_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_python(inputs, weights):\n",
    "    batch_output = []\n",
    "    for sample in inputs:\n",
    "        # Calculate output for one sample\n",
    "        sample_output = []\n",
    "        for j in range(len(weights[0])):  # For each output neuron\n",
    "            # Dot product of input (with bias) and weights\n",
    "            neuron_output = 0\n",
    "            for i in range(len(sample)):\n",
    "                neuron_output += sample[i] * weights[i][j]\n",
    "            \n",
    "            # Apply ReLU activation: max(0, x)\n",
    "            sample_output.append(max(0, neuron_output))\n",
    "        batch_output.append(sample_output)\n",
    "    return batch_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same operation in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_numpy(inputs, weights):\n",
    "    return np.maximum(0, inputs @ weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(\n",
    "    forward_pass_python(inputs, weights),\n",
    "    forward_pass_numpy(inputs_np, weights_np),\n",
    "    atol=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 ms ± 4.97 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "time_py = %timeit -o -r 10 -n 10 forward_pass_python(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 μs ± 24.8 μs per loop (mean ± std. dev. of 10 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "time_np = %timeit -o -r 10 -n 1000 forward_pass_numpy(inputs_np, weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy speedup: 786.18x\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 5))\n",
    "plt.bar(['Native Python', 'NumPy'], [time_py.average, time_np.average], width=0.4)\n",
    "plt.ylabel('Execution Time [sec]')\n",
    "print(f\"NumPy speedup: {time_py.average / time_np.average:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Technical part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center>\n",
    "<img src='images/num.png' width=600>\n",
    "</center>\n",
    "<br>\n",
    "<center>\n",
    "<img src='images/pytorch-logo-dark.png' width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "- Acceleration framework\n",
    "- Initial release: 2006 (before deep learning was mainstream)\n",
    "- Not optimized for GPUs\n",
    "- Parts of this lecture are based on the [official documentation](https://numpy.org/doc/stable/user/basics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `pip install numpy` for installation\n",
    "* `np` is an *alias* specified by the `as` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Numpy version used by me in this lecture.\n",
    "# Not that other lectures/the exam may use a different version.\n",
    "# As of Nov 2024, we plan to use numpy 1.x (not 2.x) in the exam to avoid compatibility issues.\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "- Release year: 2016\n",
    "- Optimized for GPU computation\n",
    "- NumPy syntax often generalizes to GPU-acceleration frameworks like PyTorch\n",
    "- [Documentation](https://pytorch.org/docs/stable/index.html)\n",
    "- Install via `pip install torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# As of Nov 2024, we plan to use torch 2.x in the exam\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further acceleration frameworks not covered in this lecture\n",
    "- Similar level of abstraction as numpy/torch\n",
    "  - JAX (e.g., good for JIT, TPUs)\n",
    "  - Note: most frameworks with similar abstraction as numpy/torch have similar syntax (as this minimizes barrier of entry)\n",
    "- Lower level of abstraction\n",
    "  - Triton (e.g., good for custom GPU kernels)\n",
    "- Higher level of abstraction\n",
    "  - Keras (can use multiple backends like torch or JAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Array creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Array creation from iterables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create numpy arrays from iterables like lists or tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]),\n",
       " array([1., 2., 3., 4.]),\n",
       " dtype('int64'),\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.array([1, 2, 3, 4])\n",
    "array2 = np.array((1, 2.0, 3, 4))  # array datatype equivalent to highest-precision input type\n",
    "\n",
    "array1, array2, array1.dtype, array2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change datatype of existing array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3.]), dtype('float64'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1, 2, 3])\n",
    "array = array.astype(float)\n",
    "array, array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify datatype for new array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1, -2,  3,  3,  4], dtype=int32), dtype('int32'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1, -2.9, 3.9, 3, 4], dtype=np.int32)\n",
    "\n",
    "# floats are converted via truncation toward zero\n",
    "array, array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying an operator to two arrays of different types, the resulting array inherits the type of the highest-precision operand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64 float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([1, 2, 3], dtype='float64')\n",
    "v2 = v1.astype('float32')\n",
    "print(v1.dtype, v2.dtype)\n",
    "(v1 + v2).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplary supported data types: `float64`, `float32`, `float16`, `int32`, `str` (usually no significant efficiency gain), `complex64`, `bool` ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are instances of `np.ndarray` (use this for typing; `np.array` is a function used to create an array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.78777778, 0.33722222, 0.78777778],\n",
       "         [4.18722222, 3.88777778, 0.33722222]]]),\n",
       " (1, 2, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.ndarray([1, 2, 3])\n",
    "array, array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing nested lists creates multi-dimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-d array with shape: (2,)\n",
      "[1 2]\n",
      "\n",
      "2-d array with shape: (2, 2)\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "3-d array with shape: (2, 2, 2)\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector = np.array([1, 2])\n",
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "for array in (vector, matrix, tensor):\n",
    "    print(f'{array.ndim}-d array with shape: {array.shape}\\n{array}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array creation routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.]]),\n",
       " array([0., 0.]),\n",
       " array([1.23, 1.23]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 2)), np.zeros(2), np.full(2, 1.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate memory without initializing values (less overhead than `np.zeros` or `np.full`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.23, 1.23])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATTENTION: uses garbage values at respective memory location, i.e., do not forget to overwrite\n",
    "np.empty(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0. , 0.5, 1. ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3), np.linspace(0., 1., 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability distribution: samples from uniform distribution over $[0, 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92760033, 0.39847221],\n",
       "       [0.06310934, 0.54596067],\n",
       "       [0.01321669, 0.60748942]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preferred syntax for newer code\n",
    "rng = np.random.default_rng()  # random number generator (local state)\n",
    "rng.random((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30195931, 0.01625658])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward compatible syntax\n",
    "np.random.rand(2)  # global state: can create problems, e.g., for multi-threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between numpy and torch (e.g., dataloading in numpy, neural net training in torch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.zeros(3)\n",
    "# \"arrays\" are called \"tensors\" in torch\n",
    "torch_tensor = torch.tensor(numpy_array)\n",
    "numpy_array = torch_tensor.numpy()\n",
    "numpy_array = np.array(torch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch shares much of the numpy syntax, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2])  # create tensor from iterable\n",
    "torch.ones(2)  # array creation routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), torch.Size([3]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array.shape, torch_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 3, dtype=torch.float32)\n",
    "print(tensor.dtype)\n",
    "tensor = tensor.to(torch.float16)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some minor syntactical differences, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/243870274.py\", line 3, in <module>\n",
      "    numpy_array.size()\n",
      "TypeError: 'int' object is not callable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch additionally supports the `size()` method for retrieving the shape\n",
    "try:\n",
    "    numpy_array.size()\n",
    "except TypeError:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "torch_tensor.shape, torch_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot provide GPUs to students –> focus on CPU computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA (Compute Unified Device Architecture): NVIDIA's parallel computing platform\n",
    "# Necessary for running code on NVIDIA GPUs\n",
    "# Note: other GPU types/platforms exist (e.g., AMD)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Simply move tensors to the GPU device\n",
    "    # Torch handles the rest in the backend –> remaining syntax mostly identical\n",
    "    tensor = torch.tensor([1, 2, 3]).to('cuda')\n",
    "else:\n",
    "    # Focus of this course\n",
    "    tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mac users can use [MPS](https://developer.apple.com/metal/pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    \"\"\"Returns the available device for torch.\n",
    "\n",
    "    Returns:\n",
    "        The GPU or the MPS device when available and the CPU device as a fallback.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking\n",
    "\n",
    "Example use case: including data from different data sources to one data batch (e.g., images from different cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.ones(3)\n",
    "v2 = np.ones(3)\n",
    "np.stack((v1, v2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.ones(3)\n",
    "v2 = torch.ones(3)\n",
    "torch.stack((v1, v2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation\n",
    "\n",
    "Example use case in generative modeling: Concatenate tokens for different modalities (like images and text) and train Transformer on it (as in Meta's [Chameleon model](https://arxiv.org/abs/2405.09818))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.ones(3)\n",
    "v2 = np.ones(3)\n",
    "np.concatenate((v1, v2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), torch.Size([6]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.ones(3)\n",
    "v2 = torch.ones(3)\n",
    "torch.concatenate((v1, v2)).shape, torch.cat((v1, v2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.cat` is not implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/2032947355.py\", line 5, in <module>\n",
      "    np.cat((v1, v2))\n",
      "    ^^^^^^\n",
      "  File \"/Users/wero/Documents/teaching/pyml/lecture/.venv/lib/python3.12/site-packages/numpy/__init__.py\", line 333, in __getattr__\n",
      "    raise AttributeError(\"module {!r} has no attribute \"\n",
      "AttributeError: module 'numpy' has no attribute 'cat'. Did you mean: 'cast'?\n"
     ]
    }
   ],
   "source": [
    "v1 = np.ones(3)\n",
    "v2 = np.ones(3)\n",
    "\n",
    "try:\n",
    "    np.cat((v1, v2))\n",
    "except AttributeError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays support the same indexing and slicing operations that lists and tuples do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(7)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "array[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4, 5, 6]),\n",
       " array([1, 2, 3]),\n",
       " array([1, 3, 5]),\n",
       " array([6, 5, 4, 3, 2, 1, 0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing (creates views / uses already assigned memory)\n",
    "array[2:], array[1:4], array[1::2], array[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are mutable:\n",
    "- We can modify values in-place without reallocating memory.\n",
    "- Newly assigned values inherit array datatype.\n",
    "- Certain operations (e.g., transposition) create a new array (more details later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 5 4]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(5)\n",
    "print(array)\n",
    "array[3] = 5.5  # 5.5 is converted to array dtype (uses already assigned memory)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays support advanced indexing (not supported by lists/tuples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1  0  1  2  3  4  5  6  7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  2, -1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(10) - 2\n",
    "print(array)\n",
    "array[[1, 4, 1]]  # multiple indices (this creates a copy in memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass another array as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [1, 1],\n",
       "        [3, 3]]),\n",
       " array([[0.48661056, 0.9960434 , 0.07506846],\n",
       "        [0.70387724, 0.59494539, 0.95264342],\n",
       "        [0.27824342, 0.23062858, 0.63568043],\n",
       "        [0.35935992, 0.16698065, 0.95224841]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.ones((3, 2), dtype='int')  # indices must be of type int\n",
    "indices[0, :] = 0\n",
    "indices[2, :] = 3\n",
    "\n",
    "rng = np.random.default_rng()  # random number generator\n",
    "array = rng.random((4, 3))\n",
    "\n",
    "indices, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 3),\n",
       " array([[[0.48661056, 0.9960434 , 0.07506846],\n",
       "         [0.48661056, 0.9960434 , 0.07506846]],\n",
       " \n",
       "        [[0.70387724, 0.59494539, 0.95264342],\n",
       "         [0.70387724, 0.59494539, 0.95264342]],\n",
       " \n",
       "        [[0.35935992, 0.16698065, 0.95224841],\n",
       "         [0.35935992, 0.16698065, 0.95224841]]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 x 2 times (shape of `indices`), select column from `array`\n",
    "array[indices].shape, array[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing via tuples vs. lists/arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2],\n",
       "        [3, 4, 5]]),\n",
       " 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(6).reshape(2, 3)\n",
    "array, array[(1, 0)]  # Retrieve the element at row 1, column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2],\n",
       "        [3, 4, 5]]),\n",
       " array([[0, 1, 2],\n",
       "        [3, 4, 5]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[[0, 1]], array[np.array([0, 1])]  # Retrieve rows 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some minor differences in syntax to numpy.\n",
    "- Exemplary reason: efficiency materializes different for GPUs and CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: reverse slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy: `[::-1]` creates a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4)[::-1]  # view: uses already assigned memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse striding not supported in torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/25065265.py\", line 3, in <module>\n",
      "    torch.tensor([1,2,3])[::-1]\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "ValueError: step must be greater than zero\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "try:\n",
    "    torch.tensor([1,2,3])[::-1]\n",
    "except ValueError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse tensor using dedicated function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).flip(0)  # creates new tensor (not a view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the Python standard library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True == 1, False == 0\n",
    "True and True, 1 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays support boolean types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1]),\n",
       " dtype('int64'),\n",
       " array([False, False,  True]),\n",
       " dtype('bool'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(3) - 1\n",
    "\n",
    "array, array.dtype, (array > 0), (array > 0).dtype   # Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical AND\n",
    "Returns `True` if both values are `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False]),\n",
       " array([False,  True,  True]),\n",
       " array([False,  True, False]),\n",
       " array([False,  True, False]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = array < 1\n",
    "mask2 = array > -1\n",
    "\n",
    "# Element-wise comparison (numpy overloads dunder methods __and__ and __mul__)\n",
    "mask1, mask2, mask1 & mask2, mask1 * mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/2550793419.py\", line 3, in <module>\n",
      "    mask1 and mask2\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Compares truthy value of entire array (not element-wise)\n",
    "    mask1 and mask2\n",
    "except ValueError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical OR\n",
    "Returns `True` if one of the values are `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False]),\n",
       " array([False,  True,  True]),\n",
       " array([ True,  True,  True]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1, mask2, mask1 | mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/2230416399.py\", line 3, in <module>\n",
      "    mask1 or mask2\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Compares truthy value of entire array (not element-wise)\n",
    "    mask1 or mask2\n",
    "except ValueError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical XOR\n",
    "Returns `True` if exactly one of the values is `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False]),\n",
       " array([False,  True,  True]),\n",
       " array([ True, False,  True]),\n",
       " array([ True, False,  True]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1, mask2, mask1 != mask2, mask1 ^ mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/1981125851.py\", line 6, in <module>\n",
      "    mask1 - mask2\n",
      "    ~~~~~~^~~~~~~\n",
      "TypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1 - 0 = 1\n",
    "    # 0 - 1 = -1\n",
    "    # 1 - 1 = 0\n",
    "    # 0 - 0 = 0\n",
    "    mask1 - mask2\n",
    "except TypeError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical NOT\n",
    "Reverse truthy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True, False]), array([False, False,  True]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1, ~mask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/3380683652.py\", line 3, in <module>\n",
      "    not mask1\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Tries to convert truthy value of entire array\n",
    "    not mask1\n",
    "except ValueError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattened list of elements matching the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(6).reshape(3, 2)\n",
    "print(array)\n",
    "print(array[array < 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select first and third row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[[True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retaining original shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array * (array < 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing elements matching the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 99],\n",
       "       [99,  3],\n",
       "       [ 4,  5]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[array < 3] = 99\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12573022, -0.13210486,  0.64042265],\n",
       "       [ 0.10490012, -0.53566937,  0.36159505],\n",
       "       [ 1.30400005,  0.94708096, -0.70373524]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=0)\n",
    "array = rng.normal(0, 1, (3, 3))\n",
    "ones = np.ones((3, 3))\n",
    "zeros = np.zeros((3, 3))\n",
    "array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where the condition is true, use value from first array.\n",
    "# Where it's false, use value from second array.\n",
    "np.where(array > 0, ones, zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 2, 2]), array([0, 2, 0, 2, 0, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(array > 0) # Returns row and column indices of the elements that are greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12573022, 0.64042265, 0.10490012, 0.36159505, 1.30400005,\n",
       "       0.94708096])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[np.where(array > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch\n",
    "The NumPy syntax generalizes to Torch, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ True, False,  True, False]),\n",
       " tensor([ True, False,  True, False]),\n",
       " tensor([False,  True, False,  True]),\n",
       " tensor([ True, False,  True, False]),\n",
       " tensor([False, False, False, False]),\n",
       " tensor([False, False, False, False]),\n",
       " tensor([True, True, True, True]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.rand(4) > 0.5\n",
    "mask, mask | mask, ~mask, mask & mask, mask ^ mask, mask != mask, mask == mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions on boolean arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2],\n",
       "        [3, 4, 5]]),\n",
       " False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(6).reshape(2, 3)\n",
    "array, np.all(array < 1)  # check whether all elements evaluate to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(array < 1)  # check whether any element evaluates to True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding singleton dimensions / new axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Singleton dimension (SD) = dimension of size `1`\n",
    "- Index via `None` to add SD\n",
    "- Use-case: make array orientation explicit (will be relevant for array operations like matrix multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.ones(3)\n",
    "print(array)\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(array[None])\n",
    "array[None].shape  # add SD at the beginning –> row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 1), (3, 1))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.ones(3)\n",
    "print(array[:, None])\n",
    "array[:, None].shape, array[..., None].shape  # add SD at the end –> column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singleton dimensions can be viewed as nested lists where the outer list serves only as a structural wrapper and is not essential for representing the contained values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1), (1,), ())"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three arrays containing the value `1`\n",
    "np.array([[1]]).shape, np.array([1]).shape, np.array(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use-case: Matrix multiplication, where vector orientation matters (e.g., dot product vs. outer product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch syntax is similar to Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,4)[None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch additionally provides equivalent unsqueeze/squeeze functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "for dim in range(3):\n",
    "    print(tensor.unsqueeze(dim).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1,3,4)\n",
    "for dim in range(3):\n",
    "    print(tensor.squeeze(dim).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory layout\n",
    "\n",
    "### Python lists\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; align-items: center; margin: 20px 0;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src='images/list_memory.png' width=600 style=\"border: 1px solid #f0f0f0;\" alt=\"Memory layout\">\n",
    "  </div>\n",
    "  <div style=\"width: 80%; margin-top: 10px; text-align: center;\">\n",
    "    <p style=\"font-weight: 500; margin-bottom: 4px; font-size: 0.95em;\">Figure 3: Python list memory layout</p>\n",
    "    <p style=\"font-size: 0.8em; color: #555; font-style: italic;\">\n",
    "      Source: Adapted from Peng Qian (2023). <a href=\"https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/\" target=\"_blank\" style=\"color: #1a73e8;\">Blog post</a>\n",
    "    </p>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Numpy arrays\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; flex-direction: column; align-items: center; margin: 20px 0;\">\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src='images/array_memory.png' width=600 style=\"border: 1px solid #f0f0f0;\" alt=\"Memory layout\">\n",
    "  </div>\n",
    "  <div style=\"width: 80%; margin-top: 10px; text-align: center;\">\n",
    "    <p style=\"font-weight: 500; margin-bottom: 4px; font-size: 0.95em;\">Figure 4: Numpy array memory layout</p>\n",
    "    <p style=\"font-size: 0.8em; color: #555; font-style: italic;\">\n",
    "      Source: Adapted from Peng Qian (2023). <a href=\"https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/\" target=\"_blank\" style=\"color: #1a73e8;\">Blog post</a>\n",
    "    </p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contiguous views\n",
    "- Contiguous: Arrays stored sequentially in memory\n",
    "- Views must be contiguous before operations (due to CPU/GPU memory access patterns)\n",
    "  - $\\rightarrow$ explicit or implicit copy necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One copy: wrapping result in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 3))[0, :]  # contiguous view\n",
    "a + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two copies: making `a` contiguous and wrapping result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 3))[:,0]  # non-contiguous view\n",
    "a + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " (8,),\n",
       " array([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]]),\n",
       " array([[[0, 1],\n",
       "         [2, 3]],\n",
       " \n",
       "        [[4, 5],\n",
       "         [6, 7]]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(8)\n",
    "\n",
    "array, array.shape, array.reshape(2, 4), array.reshape(2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array size must match the product of its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/3596466439.py\", line 3, in <module>\n",
      "    array.reshape(2, 3)\n",
      "ValueError: cannot reshape array of size 8 into shape (2,3)\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "try:\n",
    "    array.reshape(2, 3)\n",
    "except ValueError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-1` is a placeholder ensuring size consistency between shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape, array.reshape(2, 4).reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array.reshape(2, 4)\n",
    "array.reshape(-1, 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy syntax mostly generalizes to Torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4)\n",
    "\n",
    "tensor1 = tensor.reshape((2, 2))  # returns copy if view not possible\n",
    "tensor2 = tensor.view((2, 2))  # returns view\n",
    "\n",
    "tensor1 == tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario A: `tensor` is contiguous:\n",
    "\n",
    "Check whether `tensor1` and `tensor2` change if `tensor` changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 0.8664]), tensor([1.0000, 0.8664]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0] = 1\n",
    "tensor1[0], tensor2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario B: `tensor` is non-contiguous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0153, 0.0275],\n",
      "        [0.9096, 0.9849],\n",
      "        [0.0411, 0.1299]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(12).reshape(6, 2)[::2]  # non-contiguous\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0153, 0.0275, 0.9096],\n",
       "        [0.9849, 0.0411, 0.1299]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = tensor.reshape(2, 3)\n",
    "tensor[0] = 99\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/484464910.py\", line 2, in <module>\n",
      "    tensor.view(-1)  # does not work on non-contiguous tensors\n",
      "    ^^^^^^^^^^^^^^^\n",
      "RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    tensor.view(-1)  # does not work on non-contiguous tensors\n",
    "except RuntimeError:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "tensor.reshape(-1).shape  # works since `reshape` returns a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition and axis permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse axis order with `.T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.78208229, 0.84453187, 0.46146128],\n",
       "        [0.1588003 , 0.7849873 , 0.66877035]]),\n",
       " array([[0.78208229, 0.1588003 ],\n",
       "        [0.84453187, 0.7849873 ],\n",
       "        [0.46146128, 0.66877035]]),\n",
       " array([[0.78208229, 0.1588003 ],\n",
       "        [0.84453187, 0.7849873 ],\n",
       "        [0.46146128, 0.66877035]]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "array = rng.random((2, 3))\n",
    "\n",
    "array, array.T, array.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use case: matmul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2), (3, 3))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(array @ array.T).shape, (array.T @ array).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.transpose` to change axes order arbitrarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 3, 4), (4, 3, 2, 1), (4, 1, 3, 2))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(2 * 3 * 4).reshape(1, 2, 3, 4)\n",
    "\n",
    "array.shape, array.T.shape, array.transpose(3, 0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition creates non-contiguous view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2],\n",
       "        [3, 4, 5]]),\n",
       " array([0, 1, 2, 3, 4, 5]),\n",
       " array([0, 3, 1, 4, 2, 5]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(6).reshape(2, 3)\n",
    "\n",
    "array, array.reshape(-1), array.T.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(3, 4)\n",
    "tensor.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.T.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.T.contiguous().is_contiguous()  # flatten memory layout explicitly (makes a copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.is_contiguous()  # original tensor is still contiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten memory layout implicitly by performing operation on non-contiguous views:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.transpose(0, 1).reshape(2, 6).is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.transpose` (unlike `np.transpose`) only works on two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/2684169078.py\", line 2, in <module>\n",
      "    torch.randn(3, 4, 5).transpose(2, 3, 5)\n",
      "TypeError: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n",
      " * (int dim0, int dim1)\n",
      " * (name dim0, name dim1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.randn(3, 4, 5).transpose(2, 3, 5)\n",
    "except TypeError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `torch.permute` otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4,3,5)\n",
    "tensor = tensor.permute(2,0,1)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1, 2, 3, 4]\n",
    "list2 = [5, 6, 7, 8]\n",
    "\n",
    "# the `+` operator for lists is concatenation, not elementwise addition (the `*` is not supported on lists)\n",
    "list1 + list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: inefficient / not close to formal (mathematical) notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 10, 12]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sidenote: zip() returns iterator that implements __iter__ and __next__\n",
    "list3 = [x + y for x, y in zip(list1, list2)]\n",
    "\n",
    "list3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  8, 10, 12]), array([ 5, 12, 21, 32]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = np.array(list1)\n",
    "array2 = np.array(list2)\n",
    "\n",
    "array1 + array2, array1 * array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of example element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output of elementwise-operations for [0 1 2 3 4] and [2.5 2.5 2.5 2.5 2.5]\n",
      "[2.5 3.5 4.5 5.5 6.5]\n",
      "[ 0.   2.5  5.   7.5 10. ]\n",
      "[0.  0.4 0.8 1.2 1.6]\n",
      "[ 0.          1.          5.65685425 15.58845727 32.        ]\n",
      "[0.  1.  2.  0.5 1.5]\n",
      "\n",
      "Output of elementwise-operations for tensor([0, 1, 2, 3, 4], dtype=torch.int32) and tensor([2.5000, 2.5000, 2.5000, 2.5000, 2.5000])\n",
      "tensor([2.5000, 3.5000, 4.5000, 5.5000, 6.5000])\n",
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n",
      "tensor([0.0000, 0.4000, 0.8000, 1.2000, 1.6000])\n",
      "tensor([ 0.0000,  1.0000,  5.6569, 15.5885, 32.0000])\n",
      "tensor([0.0000, 1.0000, 2.0000, 0.5000, 1.5000])\n"
     ]
    }
   ],
   "source": [
    "def print_overview(data1, data2):\n",
    "    print(f'\\nOutput of elementwise-operations for {data1} and {data2}')\n",
    "    operations = (\n",
    "    data1 + data2,\n",
    "    data1 * data2,\n",
    "    data1 / data2,\n",
    "    data1 ** data2,\n",
    "    data1 % data2,\n",
    "    )\n",
    "    for op in operations:\n",
    "        print(op)\n",
    "\n",
    "\n",
    "# Side note: notice the type conversions\n",
    "print_overview(np.arange(5, dtype='int'), np.full(5, 2.5))\n",
    "print_overview(torch.arange(5, dtype=torch.int32), torch.full((5,), 2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axis-reducing functions\n",
    "Use the `axis` keyword to apply functions along specific dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26161213 0.29849114 0.81422574 0.09191594]\n",
      " [0.60010053 0.72856053 0.18790107 0.05514663]] \n",
      "\n",
      "[[ True  True  True False]\n",
      " [ True  True  True False]] \n",
      "\n",
      "False \n",
      "\n",
      "[ True  True  True False] \n",
      "\n",
      "[False False] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=2)\n",
    "array = rng.random((2, 4))\n",
    "\n",
    "print(array, \"\\n\")\n",
    "print(array > 0.1, \"\\n\")\n",
    "print(np.all(array > 0.1), \"\\n\")\n",
    "print(np.all(array > 0.1, axis=0), \"\\n\")\n",
    "print(np.all(array > 0.1, axis=1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 4), (2,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape, np.all(array > 0.1, 1).shape  # positional axis argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keepdims` argument retains singleton dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), (2, 1))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(array > 0.1, 1).shape, np.all(array > 0.1, 1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of such convenience functions behave similarly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 66, 210]),\n",
       " array([ 6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17.]),\n",
       " 6.922186552431729,\n",
       " 47.916666666666664)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(24).reshape(2, 12)\n",
    "np.sum(array, 1), np.mean(array, 0), np.std(array), np.var(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([True, False]), np.sum([0, 1, 2])  # passing iterables is OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object-oriented syntax (requires `ndarray` instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 66, 210])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction over a set of axes possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]),\n",
       " 276,\n",
       " 276,\n",
       " 276)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array, np.sum(array), np.sum(array, axis=(0, 1)), array.sum((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar syntax in torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 4, 6]), torch.Size([23, 4]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(23, 4, 6).shape, torch.rand(23, 4, 6).sum(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "- Example: Scale weight matrix by a constant\n",
    "- Broadcasting: Perform operations on arrays of different shapes\n",
    "    - Smaller array auto-expands to match dimensions\n",
    "- Advantages\n",
    "    - Fast\n",
    "    - Memory-efficient (no actual data duplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual example: vector and scalar\n",
    "<img src='./images/broad-vector-scalar.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture uses the below notation to describe array shapes:\n",
    "```\n",
    "a      (1d array): 3    | Equivalent to shape tuple (3,)\n",
    "b      (1d array): 1\n",
    "result (1d array): 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 5]), (3,))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2])\n",
    "result = a + b\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar does not have to be numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 5]), (3,))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = 2\n",
    "result = a + b\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the name \"broadcasting\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is reminiscent of broadcasting television: a constant message is delivered to many users:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='images/broadcast.png', width=500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General rules for determining the output shape\n",
    "\n",
    "1. If input arrays have different shapes: prepend dimensions of `1` to input array of smaller size until shape lengths align. We now have:\n",
    "   - Input shapes: $a = (a_1, \\dots, a_i, \\dots, a_n)$, $b = (b_1, \\dots, b_i, \\dots, b_n)$\n",
    "   - Output shape (unknown): $c = (s_1, \\dots, s_i, \\dots, s_n)$\n",
    "2. Determine $c$ by comparing $a$ and $b$ from the last to the first:\n",
    "   - If $a_i = b_i$, set $c_i = a_i$.\n",
    "   - If one of $a_i$ or $b_i$ is $1$, set $c_i$ as the larger value.\n",
    "   - Error: if $a_i \\neq b_i$ and neither is $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual example: 2d arrays (one broadcast)\n",
    "<img src='./images/broad-2d-one-bc.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (2d array): 4 x 3    | Equivalent to shape tuple (4, 3)\n",
    "b      (2d array): 1 x 3\n",
    "Result (2d array): 4 x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 3), (3,), (4, 3))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0, 0, 0],\n",
    "              [10, 10, 10],\n",
    "              [20, 20, 20],\n",
    "              [30, 30, 30]])\n",
    "\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "a.shape, b.shape, (a + b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, define shape of b explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (1, 3), (4, 3))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape, b[None].shape, (a + b[None]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap on defining shapes explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None].shape  # prepend singleton dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, None].shape  # add singleton dim to second dimension (`:` is a placeholder for one dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..., None].shape  # append singleton dim (`...` is a placeholder for all dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual example: 2d arrays (two broadcasts)\n",
    "<img src='./images/broad-2d-two-bc.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (2d array): 4 x 1\n",
    "b      (2d array): 1 x 3\n",
    "Result (2d array): 4 x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), (3,), (4, 3))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0], [10], [20], [30]])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "a.shape, b.shape, (a + b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual example: broadcasting error\n",
    "<img src='./images/broad-error.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (2d array): 4 x 3\n",
    "b      (2d array): 1 x 4         | 4 does not align with 3 –> error\n",
    "Result           : ValueError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6v/_tdl0v6d7t1069wv11zmprnm0000gn/T/ipykernel_98850/2111081348.py\", line 9, in <module>\n",
      "    a + b\n",
      "    ~~^~~\n",
      "ValueError: operands could not be broadcast together with shapes (4,3) (4,) \n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0, 0, 0],\n",
    "              [10, 10, 10],\n",
    "              [20, 20, 20],\n",
    "              [30, 30, 30]])\n",
    "\n",
    "b = np.array([1, 2, 3, 4])\n",
    "\n",
    "try:\n",
    "    a + b\n",
    "except ValueError:\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-dimensional example & equivalence of syntax in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 1, 2, 3]),\n",
       " torch.Size([20, 4, 1, 3]),\n",
       " torch.Size([20, 4, 2, 3]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = torch.Generator().manual_seed(42)\n",
    "t1 = torch.randn((20, 2, 3), generator=gen)\n",
    "t2 = torch.randn((20, 4, 3), generator=gen)\n",
    "\n",
    "t1 = t1[:, None]\n",
    "t2 = t2[:, :, None]\n",
    "\n",
    "t1.shape, t2.shape, (t1 + t2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commutativity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observation: order of inputs irrelevant for output **shape**\n",
    "- Question: is order of inputs generally (shapes **and** values) relevant?\n",
    "    - If arithmetic operation is commutative (like addition): order does not matter\n",
    "    - Otherwise, values depend on order of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "```\n",
    "a      (2d array): 4 x 3\n",
    "b      (2d array): 4 x 1\n",
    "Result (2d array): 4 x 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()  # random number generator\n",
    "a = rng.random((4, 3))\n",
    "b = rng.random((4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes are always identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 3), (4, 3), (4, 3), (4, 3))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a + b).shape, (b + a).shape, (a - b).shape, (b - a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are not always identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((a + b) == (b + a)), np.all((a - b) == (b - a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application example: pairwise distance matrix\n",
    "\n",
    "Example use case:\n",
    "- Search engine:\n",
    "  - creates lower-dimensional embeddings\n",
    "  - maps user queries to training data in embedding space\n",
    "- What we need: distances between all training and test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Description\n",
    "\n",
    "- Training data: $X_{\\text{tr}} \\in \\mathbb{R}^{N \\times D}$\n",
    "- Test data: $X_{\\text{te}} \\in \\mathbb{R}^{M \\times D}$\n",
    "- Goal: Compute L1 distances: $D_{ij} = \\sum_k \\left| X_{\\text{tr}, i, k} - X_{\\text{te}, j, k} \\right|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach via Python's standard library\n",
    "\n",
    "Problem: inefficient (no parallelization) and overly verbose syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [[0.1, 0.2], [0.4, 0.5], [0.3, 0.6], [0.2, 0.4]]  # N=4, D=2\n",
    "test_data = [[0.1, 0.1], [0.2, 0.3], [0.1, 0.2]]  # M=3, D=2\n",
    "\n",
    "distance_matrix = [[sum(abs(t[d] - x[d]) for d in range(len(t))) for x in test_data] for t in train_data]\n",
    "\n",
    "len(distance_matrix), len(distance_matrix[0])  # shape (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.1, 0.19999999999999998, 0.0],\n",
       " [0.7000000000000001, 0.4, 0.6000000000000001],\n",
       " [0.7, 0.39999999999999997, 0.6],\n",
       " [0.4, 0.10000000000000003, 0.30000000000000004]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach via broadcasting\n",
    "\n",
    "Efficient and compact syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N=4, M=3, D=2\n",
    "train = np.array(train_data)  # (N, D)\n",
    "test = np.array(test_data)  # (M, D)\n",
    "\n",
    "train = train[:, None]  # (N, 1, D)\n",
    "\n",
    "diff = train - test  # shape (N, M, D) <– broadcast along M, i.e., compare each training sample with all test samples\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.2, 0. ],\n",
       "       [0.7, 0.4, 0.6],\n",
       "       [0.7, 0.4, 0.6],\n",
       "       [0.4, 0.1, 0.3]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(diff), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.2, 0. ],\n",
       "       [0.7, 0.4, 0.6],\n",
       "       [0.7, 0.4, 0.6],\n",
       "       [0.4, 0.1, 0.3]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.array(train_data)  # (N, D)\n",
    "test = np.array(test_data)  # (M, D)\n",
    "\n",
    "np.sum(np.abs(train[:, None] - test), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further applications\n",
    "- Normalization (e.g., batch normalization)\n",
    "- Computing attention scores in Transformers\n",
    "- Loss functions\n",
    "- Feature masking\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplications (matmuls) are a core component of neural networks:\n",
    "- Matrix multiplications: geometric transformations (translation, rotation, etc.)\n",
    "- If you are very rusty on Linear Algebra basics, check out [this 3Blue1Brown YouTube series](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab).\n",
    "- Combined with non-linear activations –> expressive models\n",
    "  - Example for non-linear activation: broadcasting ReLu activation on array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual intuition\n",
    "We can visualizes matmuls as 3D cubes (optionally projected onto 2D surface)\n",
    "\n",
    "<center>\n",
    "<img src='images/matmul.png'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a cell in the output (`L@R`) by:\n",
    "- Taking the dot product of the vectors that extend along the corresponding row and column (from `L` and `R`)\n",
    "- `blue` + `blue` = `blue`\n",
    "- `blue` + `red` = `red`\n",
    "- `red` + `red` = `blue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How this is helpful:\n",
    "1. Easily see resulting shape\n",
    "2. Gain intuition by visualizing complex matrix operations as cubes (e.g., see [PyTorch blog](https://pytorch.org/blog/inside-the-matrix/) visualizing matmul in attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy/torch syntax\n",
    "- The `@` operator specifies matrix multiplication between two arrays\n",
    "- Operation implemented via `__matmul__` dunder method (can be overloaded or overwritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), (3, 2), (2, 2))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2,3))\n",
    "b = np.ones((3,2))\n",
    "a.shape, b.shape, (a @ b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit axis expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We treat \"axis\" as a synonym to \"dimension\"\n",
    "- Recap (broadcasting): implicit axis expansion –> prepend 1s to shorter array\n",
    "- Matmul:\n",
    "  - Array orientation interpreted to achieve valid matmul\n",
    "  - Implicit dims remain implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (2d array): 2 x 3\n",
    "b      (1d array): 3        | orientation implicit\n",
    "Result (1d array): 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 3))\n",
    "b = np.ones(3)  # assumed to be column vector\n",
    "(a @ b).shape  # orientation implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (2d array): 2 x 3\n",
    "b      (2d array): 3 x 1    | orientation explicit\n",
    "Result (2d array): 2 x 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 3))\n",
    "b = np.ones((3, 1))\n",
    "(a @ b).shape  # orientation explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "a      (1d array): 2\n",
    "b      (2d array): 2 x 3\n",
    "Result (1d array): 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(2)  # assumed to be row vector\n",
    "b = np.ones((2, 3))\n",
    "(a @ b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product vs. outer product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, ())"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.ones(2,)\n",
    "result = v @ v  # Treated as dot product and not outer product\n",
    "result, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, None] @ v[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.outer` flattens the input array. This can make code maintainability more difficult:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple unproblematic example\n",
    "v = np.ones((2,))\n",
    "np.outer(v, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.ones((2, 2))\n",
    "np.outer(v, v)  # input arrays are flattened before computing the outer product (can lead to misunderstandings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matmul on high-dimensional tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example problem\n",
    "```\n",
    "a      (4d array): 4 x 1 x 5 x 3\n",
    "b      (3d array): 5 x 3 x 2\n",
    "Result           : ?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "1. Consider matmul over last two dims, respectively\n",
    "2. Apply broadcasting rules to remaining dims\n",
    "    - Intuition: apply matmul several times with differing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: isolate matmul:\n",
    "```\n",
    "a      (2d array): 5 x 3\n",
    "b      (2d array): 3 x 2\n",
    "Result (2d array): 5 x 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((5, 3))\n",
    "b = np.ones((3, 2))\n",
    "(a @ b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: broadcasting rules:\n",
    "```\n",
    "a      (2d array): 4 x 1\n",
    "b      (2d array): 1 x 5    | axis expansion: prepend 1 until array shapes align\n",
    "Result (2d array): 4 x 5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((4, 1))\n",
    "b = np.ones((5,))\n",
    "(a + b).shape  # operator usually irrelevant, we just want to verify shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine steps (1-2):\n",
    "```\n",
    "a      (4d array): 4 x 1 x 5 x 3\n",
    "b      (3d array): 1 x 5 x 3 x 2   | expanded first dim\n",
    "Result (4d array): 4 x 5 x 5 x 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 5, 5, 2), (4, 5, 5, 2))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((4, 1, 5, 3))\n",
    "b = np.ones((5, 3, 2))\n",
    "(a @ b).shape, (a @ b[None]).shape  # implicit and explicit dim expansion results in same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch syntax is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 5, 2])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(4, 1, 5, 3)\n",
    "b = torch.rand(5, 3, 2)\n",
    "c = a @ b\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate the above manually (this is inefficient; only for educational purposes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()  # random number generator\n",
    "a = rng.random((4, 1, 5, 3))\n",
    "b = rng.random((5, 3, 2))\n",
    "\n",
    "result = np.empty((4, 5, 5, 2))  # allocate memory\n",
    "\n",
    "# Perform the operation manually\n",
    "for i in range(a.shape[0]):\n",
    "    for j in range(b.shape[0]):\n",
    "        # Second dim of `a` is broadcasted \"across `j`\"\n",
    "        a_slice = a[i, 0]  # (5, 3)\n",
    "        # Implicitly expanded first dim of `b` is broadcasted \"across `i`\"\n",
    "        b_slice = b[j]  # (3, 2)\n",
    "        result[i, j] = a_slice @ b_slice  # (5, 2)\n",
    "        \n",
    "np.allclose(result, a @ b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture continues next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Thank you for your attention!</h1>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
